INFO:main:Namespace(sut_server=['http://10.0.0.14:8008', 'http://10.0.0.12:8008'], dataset='coco-1024', dataset_path='/root/CM/repos/local/cache/61dd835801c542a3/install', profile='stable-diffusion-xl-pytorch', scenario='Offline', max_batchsize=1, threads=1, accuracy=False, find_peak_performance=False, backend='pytorch', model_name='stable-diffusion-xl', output='/root/CM/repos/local/cache/d549713c4a534705/test_results/aqua-reference-rocm-pytorch-v2.6.0.dev20241118-scc24-main/stable-diffusion-xl/offline/performance/run_1', qps=None, model_path='/root/CM/repos/local/cache/c4b6bbbebe504f28/stable_diffusion_fp16', dtype='fp16', device='cuda', latent_framework='torch', mlperf_conf='mlperf.conf', user_conf='/root/CM/repos/mlcommons@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/4230b77fd5cb4bafb0486eb50444b67d.conf', audit_conf='audit.config', ids_path='/root/CM/repos/local/cache/61dd835801c542a3/install/sample_ids.txt', time=None, count=None, debug=False, performance_sample_count=5000, max_latency=None, samples_per_query=8)
WARNING:backend-pytorch:Model path not provided, running with default hugging face weights
This may not be valid for official submissions
Keyword arguments {'safety_checker': None} are not expected by StableDiffusionXLPipeline and will be ignored.
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Using the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.
Loading pipeline components...:  57%|█████▋    | 4/7 [00:00<00:00, 17.02it/s]Loading pipeline components...:  86%|████████▌ | 6/7 [00:00<00:00,  7.51it/s]Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.41it/s]
RETURNED from requests.post on predict at time 	 1731969085.0292747
BEFORE lg.QuerySamplesComplete(response)
AFTER lg.QuerySamplesComplete(response)
RETURNED from requests.post on predict at time 	 1731969315.4215434
BEFORE lg.QuerySamplesComplete(response)
AFTER lg.QuerySamplesComplete(response)
